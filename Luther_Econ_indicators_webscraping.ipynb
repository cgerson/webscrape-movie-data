{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import fnmatch\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from texttable import Texttable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe of economic indicators by month Jan 1945 - Dec 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_econ = pd.read_excel(\"Luther_excel.xlsx\",set_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>USREC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1945-02-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1945-03-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1945-04-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1945-05-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month  USREC\n",
       "0  1945-01-01      0\n",
       "1  1945-02-01      0\n",
       "2  1945-03-01      1\n",
       "3  1945-04-01      1\n",
       "4  1945-05-01      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_econ.columns = ['Month','USREC']\n",
    "df_econ['Month'] = df_econ['Month'].map(lambda x: datetime.date(x))\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Create list of recessionary periods (by month)\n",
    "\n",
    "rec_months = list(df_econ[df_econ['USREC']==1].Month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape actors names, total gross and number of movies from Box Office Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actors_FULL,tot_gross_FULL,num_movies_FULL = [],[],[]\n",
    "pages = [1,2,4,8]\n",
    "\n",
    "for i in pages:\n",
    "\n",
    "    url = \"http://www.boxofficemojo.com/people/?view=Actor&pagenum=\"+str(i)+\"&sort=sumgross&order=DESC&adjust_yr=2015&adjust_mo=&&p=.htm\"\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "\n",
    "    #ACTORS\n",
    "    for link in soup.find_all('a',attrs = {'href':re.compile('/chart/')}):\n",
    "        [actors_FULL.append(str(a.text)) for a in link.find_all('b')]    \n",
    "\n",
    "    #TOTAL GROSS\n",
    "    for link in soup.find_all('td',attrs = {'align':\"right\"}):\n",
    "        [tot_gross_FULL.append(g.text.replace(\"$\",\"\").replace(\",\",\"\").replace(\"k\",\"\")) \n",
    "         for g in link.find_all('b')]\n",
    "    \n",
    "    #NUMBER OF MOVIES\n",
    "    for n in soup.find_all('td')[12::7]:\n",
    "        num_movies_FULL.append(int(n.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with data from Box Office Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot_gross_fl_FULL = [float(x) for x in tot_gross_FULL]\n",
    "d = zip(actors_FULL,tot_gross_fl_FULL,num_movies_FULL)\n",
    "df = pd.DataFrame(d)\n",
    "df.columns = ['Actor','Total_Gross_2015_Dol','Num_Movies']\n",
    "df = df.drop(df.index[726:])\n",
    "df['Avg_Gross'] = (df['Total_Gross_2015_Dol']/df['Num_Movies']).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Oscar data from 1960 - 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = range(1061,1065)\n",
    "\n",
    "for c in categories:\n",
    "    url = \"http://awardsdatabase.oscars.org/ampas_awards/BasicSearch\"\n",
    "    data = {'action': 'performSearch',\n",
    "                'BSFromYear': 53,\n",
    "                'BSToYear': 87,\n",
    "                'BSCategory': c,\n",
    "               'displayType': 1}\n",
    "    response = requests.post(url, data=data)\n",
    "\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "\n",
    "    for name in soup.find_all('a',attrs = {'href':re.compile('BSNominationID')}):\n",
    "            osc_names.append(name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape number of Oscar nominations for each actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oscar_actors = list(df[df['Oscar']==1].Actor)\n",
    "\n",
    "d = {actor: [] for actor in oscar_actors}\n",
    "for actor in oscar_actors:    \n",
    "#for c in categories:\n",
    "    url = \"http://awardsdatabase.oscars.org/ampas_awards/BasicSearch\"\n",
    "    data = {'action': 'performSearch',\n",
    "                    'BSNominee': actor,    \n",
    "                    'BSFromYear': 33,\n",
    "                        'BSToYear': 87,\n",
    "                        'BSCategory': 0,\n",
    "                       'displayType': 6}\n",
    "    response = requests.post(url, data=data)\n",
    "\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "\n",
    "    for year in soup.find_all('a',attrs = {'href':re.compile('(?<=displayType=1&)BSFromYear')}):\n",
    "            d[actor].append(year.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Convert years of Oscar nominations to dataframe and merge\n",
    "df_oscar_yrs = pd.DataFrame(d.items())\n",
    "df_oscar_yrs.columns = ['Actor','Years_Oscar']\n",
    "df_oscar_yrs['Years_Oscar']=df_oscar_yrs['Years_Oscar'].map(lambda x: [year[:4] for year in x]) #extract only year\n",
    "new_df = pd.merge(df,df_oscar_yrs,on='Actor',how='outer').fillna(0) #merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Create new column for number of oscar nominations based on number of years\n",
    "new_df['Years_Oscar'] = new_df['Years_Oscar'].map(lambda x: [str(unicode(i)) for i in x])\n",
    "new_df['Num_Osc'] = new_df['Years_Oscar'].map(lambda x: len(x) if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Convert Oscar winners/nominees to strings\n",
    "#### And create column based on Oscar win/nomination    \n",
    "    \n",
    "l_oscars = []\n",
    "\n",
    "for name in osc_names:\n",
    "    try:\n",
    "        l_oscars.append(str(name))\n",
    "    except:\n",
    "        continue\n",
    "            \n",
    "df['Oscar']=df['Actor'].map(lambda x: 1 if x in l_oscars else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Write birthday data for every actor in df to csv file birthdays.csv    \n",
    "\n",
    "with open(\"birthdays.csv\", 'a') as f: \n",
    "    writer=csv.writer(f)\n",
    "\n",
    "    for actor in df.Actor[700:]:\n",
    "        new_name = actor.replace(\" \",\"_\")\n",
    "        url = \"https://en.wikipedia.org/wiki/\"+new_name\n",
    "\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page,\"html.parser\")\n",
    "\n",
    "    #for line in soup.find_all('span',attrs = {'class':re.compile('BSNominationID')}):):\n",
    "        try:\n",
    "            for line in soup.find(class_=\"bday\"):\n",
    "                writer.writerow((actor,line))\n",
    "        except:\n",
    "            writer.writerow((actor,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Strip white space off birthdays when reading csv data\n",
    "\n",
    "def strip(text):\n",
    "    try:\n",
    "        return text.strip().replace('\\n',\", \")\n",
    "    except AttributeError:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Merge birthday data into dataframe\n",
    "\n",
    "df_birthdays = pd.read_csv(\"birthdays.csv\", converters={'Birthday':strip})\n",
    "new_df = pd.merge(df,df_birthdays,on='Actor',how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Wikipedia for occupation of each actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Search for occupations on Wikipedia by Actor name\n",
    "\n",
    "with open(\"occupations.csv\", 'a') as f: \n",
    "    writer=csv.writer(f)\n",
    "\n",
    "    for actor in df.Actor[700:]:\n",
    "        new_name = actor.replace(\" \",\"_\")\n",
    "        url = \"https://en.wikipedia.org/wiki/\"+new_name\n",
    "\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page,\"html.parser\")\n",
    "\n",
    "        try:\n",
    "            writer.writerow((actor,soup.find(class_=\"role\").text))\n",
    "        except:\n",
    "            try:\n",
    "                writer.writerow((actor,soup.find(scope_=\"Occupation\").text))\n",
    "            except:\n",
    "                try: \n",
    "                    url = \"https://en.wikipedia.org/wiki/\"+new_name+\"_(actor)\"\n",
    "                    response = requests.get(url)\n",
    "                    page = response.text\n",
    "                    soup = BeautifulSoup(page,\"html.parser\")\n",
    "                    writer.writerow((actor,soup.find(class_=\"role\").text))\n",
    "                except:\n",
    "                    try:\n",
    "                        writer.writerow((actor,soup.find(scope_=\"Occupation\").text))\n",
    "                    except:\n",
    "                        writer.writerow((actor,\"None\"))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Read Occupations data\n",
    "df_occ = pd.read_csv(\"occupations.csv\", converters={'Occupation':strip})\n",
    "\n",
    "#### Create Gender columm\n",
    "df_occ['Gender']=df_occ['Occupation'].map(lambda x: 0 if \"actor\" in x.lower() \n",
    "                                      else 1 if \"actress\" in x.lower() else \"Unknown\")\n",
    "\n",
    "#### Dummy for people with Actors as principal occupation\n",
    "df_occ['Occ_act_dummy'] = df_occ['Occupation'].map(lambda x: 1 if x.lower().startswith(\"actor\") or x.lower().startswith(\"actress\") else \"None\" if x==\"None\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Clean whitespaces off birthday    \n",
    "\n",
    "df['Birthday'] = df['Birthday'].map(lambda x: str(x).replace(\" \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Check for whitespace in birthdays\n",
    "\n",
    "for n in df.Birthday:\n",
    "    if type(n)==str:\n",
    "        if len(n)>10:\n",
    "            print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Create dummy to measure principal occupation as Actor (1) or otherwise (0)\n",
    "\n",
    "new_df['Occ_act_dummy'] = new_df['Occupation'].map(lambda x: 1 if x.lower().startswith(\"actor\") \n",
    "                                                   or x.lower().startswith(\"actress\") else \"None\" if x==\"None\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Create Gender dummy based on occupation\n",
    "\n",
    "new_df['Gender']=new_df['Occupation'].map(lambda x: 0 if \"actor\" in x.lower() \n",
    "                                          else 1 if \"actress\" in x.lower() else \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Create age window, ages i to j\n",
    "\n",
    "def age_range(bday,i=15,j=20):\n",
    "    date_list = [datetime.date(datetime(bday.year,bday.month,1)) + \n",
    "                 relativedelta(months=x) for x in range(i*12, j*12)]\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Read econ csv file\n",
    "#### Count number of months in recessionary period in desired time range\n",
    "\n",
    "df_econ = pd.read_excel(\"/Users/loraanngerson/Metis/github/webscrape-movie-data/data/Luther_excel.xlsx\",set_index=True)\n",
    "df_econ.columns = ['Month','USREC']\n",
    "df_econ['Month'] = df_econ['Month'].map(lambda x: datetime.date(x))\n",
    "rec_months = list(df_econ[df_econ['USREC']==1].Month)\n",
    "\n",
    "\n",
    "def count_rec_pd(actors_dates):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for d in actors_dates:\n",
    "        if d in rec_months:\n",
    "            count+=1 \n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Calculate age\n",
    "\n",
    "def calc_age(bday):\n",
    "    today = datetime.date(datetime.now(pytz.utc))\n",
    "    return today.year - bday.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Check if lists have elements in common\n",
    "\n",
    "def lists_overlap(a, b):\n",
    "    return bool(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Wikipedia for actor career length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "active = []\n",
    "for actor in actors_3:\n",
    "    new_name = actor.replace(\" \",\"_\")\n",
    "    url = \"https://en.wikipedia.org/wiki/\"+new_name\n",
    "\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,\"html.parser\")\n",
    "\n",
    "    try:\n",
    "        for line in soup.find(class_=re.compile('infobox')).find_all(string=re.compile('^Years')):\n",
    "            active.append((actor,line.find_next().string))\n",
    "    except:\n",
    "        try: \n",
    "            url = \"https://en.wikipedia.org/wiki/\"+new_name+\"_(actor)\"\n",
    "            response = requests.get(url)\n",
    "            page = response.text\n",
    "            soup = BeautifulSoup(page,\"html.parser\")\n",
    "            for line in soup.find(class_=re.compile('infobox')).find_all(string=re.compile('^Years')):\n",
    "                active.append((actor,line.find_next().string))\n",
    "        except:\n",
    "            active.append((actor,\"None\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Create list of strings of \"Years active\" data   \n",
    "\n",
    "l = []\n",
    "for name,years in active:\n",
    "    if years!=None:\n",
    "        l.append((name,unicode(years).encode(\"ascii\",\"ignore\"))) # convert unicode to string\n",
    "            \n",
    "#### Separate \"Years active\" data into start and finish year \n",
    "\n",
    "list_years_active = []\n",
    "for k,v in l:\n",
    "    start,finish = v[:4],v[4:]\n",
    "    list_years_active.append([k,start,finish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Check missing values\n",
    "\n",
    "actors_3 = list(df[df['Career_start'].isnull()].Actor)\n",
    "len(actors_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Merged career start/finish data from separate scrape\n",
    "\n",
    "for l in list_years_active:\n",
    "    df.set_value(df[df['Actor']==l[0]].index, 'Career_start', l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Convert date of career start to integer\n",
    "\n",
    "df['Career_start'] = df['Career_start'].map(lambda x: int(x) if str(x).isdigit() else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Codeboook\n",
    "\n",
    "codebook = {\n",
    "    \"Actor\": \"unique ID\",\n",
    "    \"Total_Gross_2015_Dol\": \"Amount grossed by films featuring this actor\",\n",
    "    \"Num_movies\": \"Number of movies used to calculate total gross\",\n",
    "    \"Avg_Gross\": \"Total gross divided by number of movies\",\n",
    "    \"Oscar\": \"Dummy variable 1 for Oscar win/nomination\",\n",
    "    \"Birthday\": \"Actor's birthday (datetime object)\",\n",
    "    \"Occupation\": \"Individual's occupation (source: Wikipedia)\",\n",
    "    \"Gender\": \"Actor's gender based on Actor/Actress designation\",    \n",
    "    \"Occ_act_dummy\": \"Dummy variable 1 for actor as primary occupation (source: Wikipedia)\",\n",
    "    \"Num_months_rec_pd_15_20\": \"Count of months in US economic recession between ages 15-20\",\n",
    "    \"Num_months_rec_pd_0_15\": \"Count of months in US economic recession between ages 0-15\",\n",
    "    \"Age\": \"Age of actor\",\n",
    "    \"Career_start\": \"Year acting career began (source: Wikipedia)\",\n",
    "    \"Career_fin\": \"Year acting career ended (source: Wikipedia)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### New columns for number of economic recessions during certain age ranges\n",
    "df['Num_months_rec_pd_0_5']=df['Birthday'].map(lambda x: count_rec_pd(age_range(x,0,5)))\n",
    "df['Num_months_rec_pd_5_10']=df['Birthday'].map(lambda x: count_rec_pd(age_range(x,5,10)))\n",
    "df['Num_months_rec_pd_10_15']=df['Birthday'].map(lambda x: count_rec_pd(age_range(x,10,15)))\n",
    "df['Num_months_rec_pd_15_20']=df['Birthday'].map(lambda x: count_rec_pd(age_range(x,15,20)))\n",
    "df['Num_months_rec_pd_20_25']=df['Birthday'].map(lambda x: count_rec_pd(age_range(x,20,25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Years_acting']=df['Age']-df['Age_start'] \n",
    "#New column for length of career\n",
    "\n",
    "df_only_actors['Age_start'] = df_only_actors['Career_start'] - (2015 - df_only_actors['Age']) \n",
    "#New column for starting age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Remove rows with NaN values in one column\n",
    "\n",
    "df_2 = df[np.isfinite(df['Age_start'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Seaborn histogram to plot distribution\n",
    "\n",
    "sns.distplot(df.Age,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Four sublots of bar graphs \n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2,figsize=(15,10),sharex=True,sharey=True)\n",
    "axes[0,0].bar(df.Num_months_rec_pd_0_5, df.Avg_Gross,width,color='y',label=\"Age 0-5\")\n",
    "axes[0,1].bar(df.Num_months_rec_pd_5_10, df.Avg_Gross, width, color='r', label=\"Age 5-10\")\n",
    "axes[1,0].bar(df.Num_months_rec_pd_10_15, df.Avg_Gross, width, color = 'g',label=\"Age 10-15\")\n",
    "axes[1,1].bar(df.Num_months_rec_pd_15_20, df.Avg_Gross, width, label=\"Age 15-20\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
